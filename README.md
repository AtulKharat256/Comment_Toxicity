# ğŸ§  Comment Toxicity Detection

This project uses a deep learning model to detect **toxic comments** in text data. The dataset originates from the [Jigsaw Toxic Comment Classification Challenge](https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge), and the model predicts probabilities for multiple categories of toxicity.

---

## ğŸ“Š Model Objective

The goal is to classify each comment into one or more of the following categories:
- â˜£ï¸ toxic
- ğŸ‘ severe_toxic
- ğŸ¤¬ obscene
- ğŸš« threat
- ğŸ’¥ insult
- ğŸ˜¤ identity_hate

---

## ğŸ§ª Key Features in the Notebook

- âœ… Exploratory Data Analysis (EDA)
- âœ… Preprocessing: lowercasing, punctuation removal, stemming
- âœ… Vectorization using `Tokenizer`
- âœ… Model: Sequential Neural Network with `Dense`, and `ReLU` activations
- âœ… Evaluation: Accuracy, and sample prediction outputs
- âœ… Model saving in `.h5` format for later inference

---

## ğŸ“¦ Dependencies

To run this notebook, make sure you install:

```bash
pip install numpy pandas matplotlib seaborn scikit-learn tensorflow keras

## â–¶ï¸ How to Run

### ğŸ” Clone the Repository

```bash
git clone https://github.com/AtulKharat256/Comment_Toxicity.git
cd Comment_Toxicity

## Run the jupyter notebook
jupyter notebook Comment_Toxicity.ipynb

